{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of food items (Unsupervised Learning, with improved accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will attempt to classify a food items database into their appropriate segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Text Pre-processing\n",
    "3. Text-to-features (Feature Engineering)\n",
    "4. Text modelling\n",
    "5. Text Classification\n",
    "6. Testing and exporting\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following problem, we have a database 'item_list.csv' having 2 columns, item_name and item_id. The tasks are:\n",
    "\n",
    "1. To come up with appropriate segments for the food items\n",
    "2. Train a model that predicts the segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is what I did in my previous attempt:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"For the first part, I will use clustering algorithm as the problem is unsupervised. For the second part, I will extract labels from the clusters and use them as features for clustering.*\n",
    "\n",
    "*I will be using Word2Vec using gensim, as Word2Vec has the power to produce word embeddings. Other models like bag of words, tf-idf will not give us the co-relation between the words.*\n",
    "\n",
    "*As an alternative, I will also be using TextBlob with the NaiveBayesClassifier as it can give a better result than K-means using Scikit-Learn.*\n",
    "\n",
    "*I wanted to use GloVe and fastText as well, so that we could have had an overview all all models an chosen the best one.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a second attempt, I decided to use GloVe (it attempts to obtain high-dimensional vector representations of words using global word-word co-occurrence) and SpaCy (a general purpose NLP tool which also happens to include pre-trained vectors for the most common English words using the GloVe Common Crawl.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in short, I'll be making meta-labels(topic_keywords) based on my overview of the data.\n",
    "Also, I'll be defining the labels(topic_labels) before I train the model.\n",
    "\n",
    "Then, I'll convert each keyword to a vector using GloVe.\n",
    "Following which, I'll convert our data into vectors as well.\n",
    "\n",
    "Finally, I'll compute a similarity matrix of each keyword to each topic, which gives us the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Sneak-peak at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database\n",
    "dataset=pd.read_csv('item_list.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>item_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>peri peri wrap</td>\n",
       "      <td>2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gi-7161-19</td>\n",
       "      <td>24806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Milk Chocolate Tub</td>\n",
       "      <td>22729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Soft Drinks Large</td>\n",
       "      <td>12419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cheese Omellete</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           item_name     id\n",
       "0           0      peri peri wrap   2444\n",
       "1           1          gi-7161-19  24806\n",
       "2           2  Milk Chocolate Tub  22729\n",
       "3           3   Soft Drinks Large  12419\n",
       "4           4     Cheese Omellete   3421"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sneak-peak of data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28922 entries, 0 to 28921\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    28922 non-null int64\n",
      "item_name     28922 non-null object\n",
      "id            28922 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 677.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to solve the issue of not deleting the id's in the following way:\n",
    "    1. Making all required changes to data without deleting the id\n",
    "    2. Slicing and storing id column in a dataframe before modelling\n",
    "    3. Appending the id frame back to the original database\n",
    "    \n",
    "The issue in this was:\n",
    "After making all changes to data, there are less entries in the data, and thus id and data could not be concatenated as the dimensions now differ.\n",
    "\n",
    "This issue will be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns.\n",
    "dataset.drop(labels = [\"Unnamed: 0\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(labels = [\"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['peri peri wrap', 2444],\n",
       "       ['gi-7161-19', 24806],\n",
       "       ['Milk Chocolate Tub', 22729],\n",
       "       ...,\n",
       "       ['Thums Up 200 Ml', 5774],\n",
       "       ['Fruit Wine (Large)', 6561],\n",
       "       ['coca cola 300 ml', 20649]], dtype=object)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28922 entries, 0 to 28921\n",
      "Data columns (total 2 columns):\n",
      "item_name    28922 non-null object\n",
      "id           28922 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 452.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Brief information about dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_name    0\n",
       "id           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14463.499862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8349.206819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7233.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14463.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21693.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28924.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id\n",
       "count  28922.000000\n",
       "mean   14463.499862\n",
       "std     8349.206819\n",
       "min        2.000000\n",
       "25%     7233.250000\n",
       "50%    14463.500000\n",
       "75%    21693.750000\n",
       "max    28924.000000"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peri peri wrap</td>\n",
       "      <td>2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gi-7161-19</td>\n",
       "      <td>24806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk Chocolate Tub</td>\n",
       "      <td>22729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soft Drinks Large</td>\n",
       "      <td>12419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cheese Omellete</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item_name     id\n",
       "0      peri peri wrap   2444\n",
       "1          gi-7161-19  24806\n",
       "2  Milk Chocolate Tub  22729\n",
       "3   Soft Drinks Large  12419\n",
       "4     Cheese Omellete   3421"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, in this section, we have had a good look at our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is raw and has many errors. We will implement three major changes in our dataset. They are:\n",
    "    1. Convert all data to lowercase\n",
    "    2. Get rid of the punctuation\n",
    "    3. Remove numbers from dataset\n",
    "    4. Remove specific elements having no significant use (delivery charges@30, gi--)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting data to lower-case using Lambda function\n",
    "a = dataset.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = a['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we have sliced and stored id column into a dataframe df1, which will be appended again to the main database. The problem here was after removing the punctuation, it deletes the id as well for some reason. Also, the number of rows are reduced, and should be in sync with id colun before slicing it.\n",
    "\n",
    "Will fix this issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peri peri wrap</td>\n",
       "      <td>2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gi-7161-19</td>\n",
       "      <td>24806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milk chocolate tub</td>\n",
       "      <td>22729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soft drinks large</td>\n",
       "      <td>12419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheese omellete</td>\n",
       "      <td>3421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item_name     id\n",
       "0      peri peri wrap   2444\n",
       "1          gi-7161-19  24806\n",
       "2  milk chocolate tub  22729\n",
       "3   soft drinks large  12419\n",
       "4     cheese omellete   3421"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_a=a.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of all punctuation\n",
    "b=a.apply(lambda x: x.astype(str).str.replace('[^\\w\\s]',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28922, 2)"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28922 entries, 0 to 28921\n",
      "Data columns (total 2 columns):\n",
      "item_name    28922 non-null object\n",
      "id           28922 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 452.0+ KB\n"
     ]
    }
   ],
   "source": [
    "b.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=b['item_name'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        peri peri wrap\n",
       "1                                                    gi\n",
       "2                                    milk chocolate tub\n",
       "3                                     soft drinks large\n",
       "4                                       cheese omellete\n",
       "5                                            cheesy dip\n",
       "6                     blueberry cream cheese sw waffles\n",
       "7                                            cafe mocha\n",
       "8                                 exotic veg with sauce\n",
       "9                                          basket chaat\n",
       "10                                     red paprika half\n",
       "11                                oreo obsessed pancake\n",
       "12                                     raspberry medium\n",
       "13                               chicken nuggets swiggy\n",
       "14                                 chicken garlic salad\n",
       "15                                    nuts over nutella\n",
       "16                                  marshmallow brownie\n",
       "17                                      delivery charge\n",
       "18                    schezwan paneer pizza waffle half\n",
       "19                                 espresso  cappuccino\n",
       "20                                        matka chicken\n",
       "21                                    pizza waffle full\n",
       "22                                cottage cheese panino\n",
       "23                                           xtra honey\n",
       "24                                                   gi\n",
       "25                        banana  salted caramel puffle\n",
       "26                                nasty nutella pancake\n",
       "27                                  whisky black  white\n",
       "28                                             bbq wrap\n",
       "29                                       veg fried rice\n",
       "                              ...                      \n",
       "28892                                      twix pancake\n",
       "28893                                  mini pancake muo\n",
       "28894                               chicken shami kebab\n",
       "28895                                 fresh veggie full\n",
       "28896                             parle g caramel shake\n",
       "28897                                 crab pepper roast\n",
       "28898                              butter tandoori roti\n",
       "28899                                    bottled water \n",
       "28900                          aloo gobhi matar sukha n\n",
       "28901                                 chilli paneer dry\n",
       "28902                            go olives pizza medium\n",
       "28903                         blueberry cheese cake jar\n",
       "28904                                penne masala mafia\n",
       "28905                       apple cinnamon pastry shake\n",
       "28906                            chocoffe mini pancakes\n",
       "28907     kolkata meetha paan ice cream with gulkand sc\n",
       "28908                           classic vanilla cupcake\n",
       "28909                                          espresso\n",
       "28910                                  beet carrot juic\n",
       "28911                      swiggy white chocolate shake\n",
       "28912    off new link road oshiwara andheri west mumbai\n",
       "28913                            honey  butter waffwich\n",
       "28914                          crispy fried basa filled\n",
       "28915                            paneer chilli sandwich\n",
       "28916                                           granola\n",
       "28917                               nasty nutella crepe\n",
       "28918                marshmallow dark chocolate pancake\n",
       "28919                                      thums up  ml\n",
       "28920                                  fruit wine large\n",
       "28921                                     coca cola  ml\n",
       "Name: item_name, Length: 28922, dtype: object"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a pandas dataframe to a numpy array\n",
    "c=f.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['peri peri wrap', 'gi', 'milk chocolate tub', ..., 'thums up  ml',\n",
       "       'fruit wine large', 'coca cola  ml'], dtype=object)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Removing specific words having no significance (delivery charge@30, gi--3557)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and delete index having word as delivery charge@\n",
    "index = np.argwhere((c=='delivery charge@'))\n",
    "h=np.delete(c, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['peri peri wrap', 'gi', 'milk chocolate tub', ..., 'thums up  ml',\n",
       "       'fruit wine large', 'coca cola  ml'], dtype=object)"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and delete index having word as gi\n",
    "index = np.argwhere(h=='gi')\n",
    "i=np.delete(h, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['peri peri wrap', 'milk chocolate tub', 'soft drinks large', ...,\n",
       "       'thums up  ml', 'fruit wine large', 'coca cola  ml'], dtype=object)"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['peri peri wrap', 'milk chocolate tub', 'soft drinks large', ...,\n",
       "       'thums up  ml', 'fruit wine large', 'coca cola  ml'], dtype=object)"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have successfully cleaned our text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text data to vectors. I have taken the transpose of the clean data array and converted it to a list as the input parameter in the model requires a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to matrix\n",
    "x = np.matrix(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take transpose of matrix\n",
    "e=x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to array\n",
    "A = np.squeeze(np.asarray(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array to list\n",
    "keywords=np.array(A).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27715\n"
     ]
    }
   ],
   "source": [
    "# Notice that many words are removed in the cleaning process\n",
    "print(len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've considered these five labels to classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels = [\n",
    "  'Veg',\n",
    "  'Non-Veg',\n",
    "  'Non-alcoholic beverages',\n",
    "  'Alcoholic beverages',\n",
    "  'Desserts'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After taking a good look at our raw data, I've taken several keywords which can be associated with the labels. These will help us in getting a good accuracy score.*\n",
    "\n",
    "They can be further tweaked a bit to impove accuracy more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords=[\n",
    "    'veg vegetable paneer potato aloo dal cheese wrap',\n",
    "    'chicken muttton fish prawn bacon pepperoni omellete shawrma',\n",
    "    'milk tea coffee shake soup soft drinks cafe juice frappe cappuccino',\n",
    "    'beer whisky alcohol vodka mojito',\n",
    "    'mousse pancakes nutella waffles pastry choco chocolate brownie cake ice cream'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = list(nlp.pipe(topic_keywords, batch_size=10000,\n",
    "  n_threads=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vectors = np.array([doc.vector \n",
    "  if doc.has_vector else spacy.vocab[0].vector\n",
    "  for doc in topic_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32437888, -0.07631037,  0.39711875, ..., -0.6509937 ,\n",
       "         0.22559974,  0.20750675],\n",
       "       [-0.23657374, -0.14360987,  0.27317825, ..., -0.43897274,\n",
       "         0.11324563, -0.03115   ],\n",
       "       [-0.08931038, -0.01475291,  0.21033691, ..., -0.5406088 ,\n",
       "         0.14321029,  0.25229844],\n",
       "       [-0.309226  ,  0.1686554 ,  0.21253319, ..., -0.538742  ,\n",
       "         0.06441001,  0.18663299],\n",
       "       [ 0.11771746, -0.0313131 ,  0.28859174, ..., -0.66667634,\n",
       "        -0.16483046,  0.57205635]], dtype=float32)"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all topic vectors\n",
    "topic_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will input our clean data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_docs = list(nlp.pipe(keywords,\n",
    "  batch_size=10000,\n",
    "  n_threads=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = np.array([doc.vector\n",
    "  if doc.has_vector else spacy.vocab[0].vector\n",
    "  for doc in keyword_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peri peri wrap\n",
      "[ 2.59444684e-01 -1.00313336e-01  2.74570018e-01  3.72499317e-01\n",
      "  9.14593339e-02  1.02089994e-01  2.97270030e-01  2.53864348e-01\n",
      "  2.00463012e-01 -4.94766645e-02 -1.08347327e-01 -3.33615333e-01\n",
      "  4.83299971e-01 -1.47579998e-01 -2.52698004e-01 -6.33096620e-02\n",
      " -1.93663314e-01  6.65633380e-01 -8.48433375e-02 -2.49800030e-02\n",
      "  2.60699987e-02  2.33166609e-02 -6.48333356e-02  2.04908013e-01\n",
      "  2.67069995e-01 -1.19893335e-01 -3.76466662e-01 -1.29619995e-02\n",
      "  1.34786665e-01  2.52466649e-01 -1.88200027e-02  8.96866620e-03\n",
      " -3.32243323e-01 -2.12303340e-01 -1.95200052e-02  2.87405010e-02\n",
      "  1.80900678e-01 -9.51429978e-02 -8.33433270e-02  1.45624325e-01\n",
      "  1.12314664e-01  1.67680010e-01 -4.04880010e-02 -1.77794680e-01\n",
      " -2.29870006e-01 -2.37937346e-01 -3.18850666e-01 -4.10000468e-03\n",
      " -2.21501186e-01  8.62626731e-03  1.15657665e-01 -8.05592686e-02\n",
      "  4.10733335e-02 -5.39063334e-01  3.84093314e-01 -2.74853315e-02\n",
      "  8.64799786e-03  4.27119970e-01 -7.34600052e-02  8.45173374e-02\n",
      " -4.07603294e-01 -3.97296160e-01  1.16032004e-01 -8.06766674e-02\n",
      "  1.19956672e-01 -2.58736640e-01 -4.92353350e-01  1.08283341e-01\n",
      "  1.67600010e-02  5.36596663e-02 -1.43429652e-01  3.40332580e-03\n",
      " -3.02503675e-01 -1.87609002e-01  2.57859975e-01 -2.46866643e-02\n",
      " -4.09013003e-01 -5.79156697e-01 -3.08883339e-01 -1.29840001e-01\n",
      " -5.03103018e-01  4.10156637e-01  9.54036713e-02  4.85163331e-01\n",
      " -1.83212683e-01 -4.56351310e-01  1.03653002e+00  5.53240001e-01\n",
      "  9.98333320e-02 -2.14113340e-01  3.87667306e-02 -3.46650004e-01\n",
      "  1.29909322e-01 -2.73176670e-01  7.70699978e-02  1.96361348e-01\n",
      "  7.72333145e-03  2.59846658e-01 -3.07996660e-01  1.67586669e-01\n",
      "  5.76606691e-02  4.52583330e-03  4.04523343e-01  3.68324488e-01\n",
      " -4.08536673e-01 -1.12451661e+00 -4.82899956e-02 -2.85973325e-02\n",
      " -4.84946698e-01 -5.59066683e-02  3.17553312e-01 -3.04293334e-01\n",
      "  2.60023326e-01 -1.56623334e-01  2.20210329e-01  3.22876334e-01\n",
      " -3.33389997e-01 -3.36860009e-02 -1.88020006e-01  4.79926676e-01\n",
      "  4.73433323e-02 -5.33300042e-02 -9.38240066e-02  3.85163307e-01\n",
      " -1.38332939e-03 -1.98543325e-01 -8.15270022e-02  2.09759995e-01\n",
      " -3.66336666e-02 -1.89161316e-01 -5.13520002e-01 -8.63976657e-01\n",
      " -2.55589992e-01 -3.74683291e-01  2.15166658e-02 -3.63666564e-04\n",
      " -2.50563323e-01  1.54713333e-01  1.31284833e-01  2.79040009e-01\n",
      " -1.83613336e+00 -3.09807003e-01 -2.64753342e-01 -6.41833320e-02\n",
      " -4.26074356e-01  3.53403330e-01 -2.10799649e-01  1.76383331e-01\n",
      " -3.69400047e-02 -1.31378666e-01  1.86634004e-01 -3.95403981e-01\n",
      "  2.58369654e-01  3.11935663e-01  1.30066676e-02 -7.33466670e-02\n",
      " -4.68223356e-02  3.66666727e-02 -1.81600019e-01  7.22939968e-01\n",
      "  1.54699996e-01 -9.80899930e-02  5.56433313e-02 -2.51943350e-01\n",
      "  5.63006699e-02 -4.18486707e-02  1.28986659e-02  3.85610670e-01\n",
      "  3.99180017e-02 -1.23201333e-01  8.31966624e-02 -1.59404323e-01\n",
      " -3.78500037e-02 -4.29300040e-01 -2.22086668e-01  1.46863326e-01\n",
      "  2.21173316e-02  2.86433667e-01 -5.00053704e-01  1.80423677e-01\n",
      "  3.48080009e-01  2.45133284e-02  1.96511671e-02 -1.63801000e-01\n",
      "  1.70736656e-01 -8.04266799e-03 -4.25680012e-01 -3.33266668e-02\n",
      " -2.29998007e-01  5.27666695e-02 -1.14192002e-01 -4.47559983e-01\n",
      " -3.50119978e-01 -1.02040671e-01 -9.31000039e-02  1.48111999e-01\n",
      "  1.68266654e-01  2.96433326e-02  2.81299978e-01  6.72006682e-02\n",
      "  4.18163329e-01 -3.97760011e-02  2.38123331e-02  4.67566639e-01\n",
      "  2.95333075e-03  6.31006658e-02 -1.90446004e-01  3.03643346e-01\n",
      " -3.37049991e-01 -1.08039998e-01 -2.32645988e-01 -4.93866690e-02\n",
      "  5.09056628e-01 -2.54976660e-01 -3.61629993e-01 -1.06606670e-01\n",
      " -3.36603314e-01 -1.08390667e-01 -1.41659990e-01 -4.70193356e-01\n",
      "  1.67303339e-01 -3.50216657e-01 -3.56950015e-01 -2.06543013e-01\n",
      "  2.63165325e-01  3.28013331e-01  2.55483329e-01  2.11314652e-02\n",
      " -1.64633334e-01  5.96993305e-02  8.69733319e-02 -1.45225003e-01\n",
      " -1.57299995e-01  6.09405972e-02 -9.21318755e-02  1.80000011e-02\n",
      " -1.06000237e-01  1.71556666e-01 -2.77376324e-01 -1.92906320e-01\n",
      " -1.60250336e-01 -4.49039966e-01 -2.50990003e-01 -7.60800159e-03\n",
      "  1.77533999e-01  2.92280018e-02 -4.15190011e-01  7.81266615e-02\n",
      " -7.56333396e-02  1.27241328e-01  8.31799954e-02  1.42245337e-01\n",
      "  4.21259999e-01 -3.68683338e-01 -3.05803329e-01  8.07073340e-02\n",
      " -2.16083333e-01  3.21689337e-01 -1.13383330e-01  1.48757681e-01\n",
      "  3.40450019e-01  1.12279989e-01 -4.16850001e-01  6.51701316e-02\n",
      "  3.04053336e-01  1.14006668e-01  9.25666690e-02  5.95673323e-02\n",
      " -6.52749956e-01  5.44166677e-02 -6.83711588e-01  9.67160091e-02\n",
      "  7.61966631e-02  8.91773283e-01  2.65648991e-01  1.61166657e-02\n",
      " -3.57016660e-02 -2.97223330e-01  5.61533272e-02  1.88538671e-01\n",
      "  4.07840014e-01 -3.18133347e-02  1.81592330e-01  1.87890664e-01\n",
      "  1.86144009e-01 -4.93860655e-02  2.56993324e-01 -1.10339999e-01\n",
      "  1.89936683e-01 -1.59726664e-01  3.52793336e-01  1.54478669e-01\n",
      "  9.40599963e-02  3.58966701e-02  7.44666681e-02  1.28133297e-02\n",
      " -1.47535011e-01 -8.00666660e-02  4.73236680e-01 -2.57606655e-01]\n"
     ]
    }
   ],
   "source": [
    "# Vector for our data\n",
    "print(keywords[0])\n",
    "print(keyword_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Computing the cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll compute a similarity matrix of each keyword to each topic. Cosine similarity has been shown to work well for word vector similarity, so we’ll compute cross-wise similarity and then assign each keyword to the topic it is most similar to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34263933 0.2565931  0.3108404  0.1452301  0.25741756]\n",
      " [0.6251325  0.56232715 0.825355   0.5810569  0.80771744]\n",
      " [0.52496713 0.46872646 0.7803726  0.614789   0.58035344]\n",
      " ...\n",
      " [0.4013421  0.36484957 0.51594746 0.42516547 0.4331894 ]\n",
      " [0.6017383  0.54553306 0.7253492  0.63016653 0.5587209 ]\n",
      " [0.42670894 0.36803028 0.6208189  0.63371706 0.46583572]]\n"
     ]
    }
   ],
   "source": [
    "simple_sim = cosine_similarity(keyword_vectors, topic_vectors)\n",
    "topic_idx = simple_sim.argmax(axis=1)\n",
    "print(simple_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in zip(keywords, topic_idx):\n",
    "  p.append((k, topic_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "final=array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['peri peri wrap', 'Veg'],\n",
       "       ['milk chocolate tub', 'Non-alcoholic beverages'],\n",
       "       ['soft drinks large', 'Non-alcoholic beverages'],\n",
       "       ...,\n",
       "       ['thums up  ml', 'Non-alcoholic beverages'],\n",
       "       ['fruit wine large', 'Non-alcoholic beverages'],\n",
       "       ['coca cola  ml', 'Alcoholic beverages']], dtype='<U87')"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the section where we could have concatenated id back with the classified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.concatenate([final,df1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exporting final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final, columns = ['Item Name','Item Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27715 entries, 0 to 27714\n",
      "Data columns (total 2 columns):\n",
      "Item Name    27715 non-null object\n",
      "Item Type    27715 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 433.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Viewing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Item Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peri peri wrap</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milk chocolate tub</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soft drinks large</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cheese omellete</td>\n",
       "      <td>Non-Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheesy dip</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blueberry cream cheese sw waffles</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cafe mocha</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exotic veg with sauce</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>basket chaat</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>red paprika half</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oreo obsessed pancake</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>raspberry medium</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chicken nuggets swiggy</td>\n",
       "      <td>Non-Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chicken garlic salad</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nuts over nutella</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>marshmallow brownie</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>delivery charge</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>schezwan paneer pizza waffle half</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>espresso  cappuccino</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>matka chicken</td>\n",
       "      <td>Non-Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pizza waffle full</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cottage cheese panino</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xtra honey</td>\n",
       "      <td>Non-alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>banana  salted caramel puffle</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nasty nutella pancake</td>\n",
       "      <td>Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>whisky black  white</td>\n",
       "      <td>Alcoholic beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bbq wrap</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>veg fried rice</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feta greek</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>penne creamy pesto</td>\n",
       "      <td>Veg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Item Name                Item Type\n",
       "0                      peri peri wrap                      Veg\n",
       "1                  milk chocolate tub  Non-alcoholic beverages\n",
       "2                   soft drinks large  Non-alcoholic beverages\n",
       "3                     cheese omellete                  Non-Veg\n",
       "4                          cheesy dip                      Veg\n",
       "5   blueberry cream cheese sw waffles                 Desserts\n",
       "6                          cafe mocha  Non-alcoholic beverages\n",
       "7               exotic veg with sauce                      Veg\n",
       "8                        basket chaat                      Veg\n",
       "9                    red paprika half                      Veg\n",
       "10              oreo obsessed pancake                 Desserts\n",
       "11                   raspberry medium  Non-alcoholic beverages\n",
       "12             chicken nuggets swiggy                  Non-Veg\n",
       "13               chicken garlic salad                      Veg\n",
       "14                  nuts over nutella                 Desserts\n",
       "15                marshmallow brownie                 Desserts\n",
       "16                    delivery charge  Non-alcoholic beverages\n",
       "17  schezwan paneer pizza waffle half                      Veg\n",
       "18               espresso  cappuccino  Non-alcoholic beverages\n",
       "19                      matka chicken                  Non-Veg\n",
       "20                  pizza waffle full                 Desserts\n",
       "21              cottage cheese panino                      Veg\n",
       "22                         xtra honey  Non-alcoholic beverages\n",
       "23      banana  salted caramel puffle                 Desserts\n",
       "24              nasty nutella pancake                 Desserts\n",
       "25                whisky black  white      Alcoholic beverages\n",
       "26                           bbq wrap                      Veg\n",
       "27                     veg fried rice                      Veg\n",
       "28                         feta greek                      Veg\n",
       "29                 penne creamy pesto                      Veg"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, many of the items are correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thank you for reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
